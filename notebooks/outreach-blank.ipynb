{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data and Finding the \"needle in the haystack\" galaxies\n",
    "*A python excersie notebook written by Lewis McMillan, Summer 2020. This notebook has benifited from examples provided by Rita Tojeiro, and the help of Anne-Marie Weijmans, and Simon Reynolds.*\n",
    "\n",
    "In this notebook you will use data from the Sloan Digital Sky Survey (SDSS), to explore how astronomers interact with \"big data\", and how they can use various different measurments of galaxies shapes in order to find spiral galaxies, the mergering of multiple galaxies, and other interesting galaxies.\n",
    "\n",
    "## SDSS and SciServer\n",
    "\n",
    "As mentioned above, in this notebook we will use data from SDSS, which is is the largest astronmical dataset in the world currently. For eachs nights observing it generates around 200Gb of data. The laptop this notebook was written on has 256Gb of storage space, meaning that I could fit 1 nights observing data on my laptop with some space left over for all the programs I need to analysie the data.\n",
    "\n",
    "If you are reading this then we assume that you havel alredy followed the instructions to get an account on SciServer, and have uploaded this notebook. In addition to this we assume that you are familiar with basic python, dataframe manipulation, and matplotlib commands. If not please complete Rita Tojeiro's notebook's which cover these topics: link here\n",
    "\n",
    "### Install required Python libraries\n",
    "The following prompt only needs to be run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install python libraries that are needed\n",
    "!pip install dataclasses                           # needed as Python is a lower version than code needs\n",
    "!pip install astropy                               # general purpose astronomy library\n",
    "!pip install photutils                             # photomertry general purpose library\n",
    "!pip install scikit-image                          # image anaylsis general purpose library\n",
    "!pip install tqdm                                  # pretty progress bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "To get started we first install and then import all the libraries we will need in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "import pawlikMorphLSST as pmlsst                    # Library for analysing galaxies\n",
    "print(\"Galaxy analysis code imported\")\n",
    "%cd -\n",
    "\n",
    "# Import Python libraries to work with SciServer\n",
    "import SciServer.CasJobs as CasJobs                 # query with CasJobs\n",
    "import SciServer.SkyServer as SkyServer             # for getting jpg of galaxies\n",
    "print('SciServer libraries imported')\n",
    "\n",
    "# Import other libraries for use in this notebook.\n",
    "import numpy as np                                  # standard Python lib for math ops\n",
    "import pandas as pd                                 # data manipulation package\n",
    "import matplotlib.pyplot as plt                     # another graphing package\n",
    "from pathlib import Path                            # manage local files in your Compute containers\n",
    "from astropy.visualization import ZScaleInterval    # for plotting clear images\n",
    "from tqdm import tqdm_notebook                      # for a nice progress bar\n",
    "from concurrent.futures import ProcessPoolExecutor  # for running the code on more than 1 cpu\n",
    "from IPython.display import clear_output            # allow nice printing\n",
    "import time                                         # allows the timing of code\n",
    "print('Supporting libraries imported')\n",
    "\n",
    "# Apply some special settings to the imported libraries\n",
    "# ensure columns get written completely in notebook\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# for plotting clear images\n",
    "zscale = ZScaleInterval()\n",
    "\n",
    "# do *not* show python warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('Settings applied')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the SDSS database\n",
    "\n",
    "The SDSS data is stored in a SQL database. Databases can be thought of as large tables of information. SQL is  one language that can be used to communicate with databases via \"queries\". For each query command, the database returns an answer. Usually, this is a subsample of the original database, though SQL can operate on the data very effectively too. In this tutorial we will submit queries to the SDSS database to gather the information that we need, and we will use Python to operate on, manipulate, and vizualise that data.\n",
    "\n",
    "An extensive tutorial on how to query the SDSS database is provided here: http://skyserver.sdss.org/dr16/en/help/howto/search/searchhowtohome.aspx . In short, nearly every SQL command consists of three blocks:\n",
    "\n",
    "The SELECT block: it defines the quantities that you want your query to return.\n",
    "The FROM block: it defines which tables of the database you want SQL to look in.\n",
    "The WHERE block: it defines any constraints on the data that you want to impose.\n",
    "In this Lab you won't have to write SQL queries from scratch, only execute commands that are already written for you.\n",
    "\n",
    "Using SQL and SciServer to return galaxy data\n",
    "For the database schema and documentation see http://skyserver.sdss.org/dr16/en/help/browser/browser.aspx The following query returns specific information on a sample of galaxies, as a Pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find objects in the Sloan Digital Sky Survey's.\n",
    "#\n",
    "# Query the Sloan Digital Sky Serveys' NSA catalog of galactical objects.\n",
    "# For the database schema and documentation see http://skyserver.sdss.org/dr16/en/help/browser/browser.aspx?cmd=description+nsatlas+U#&&history=description+nsatlas+U\n",
    "#\n",
    "# This query finds all galaxies in the value added catalogue PawlikMorph and matches this information to the\n",
    "# MaNGA catalogue in order to get galaxies positions.\n",
    "# Finally we discard any galaxies that have incomplete measurments\n",
    "#\n",
    "# First, store the query in an object called \"query\"\n",
    "query=\"\"\"\n",
    "select distinct m.objra, m.objdec, p.A, p.[As], p.As90, p.S, p.G, p.C2080, p.C5090, p.M20, p.run, p.rerun, p.camcol, p.field\n",
    "from dbo.PawlikMorph p\n",
    "  join dbo.mangaDAPall m\n",
    "  on m.mangaID = p.mangaid\n",
    "  \"\"\"\n",
    "#where p.warningflag = 0 and p.A > -99 and p.S > -99 and p.C2080 > -99 and p.C5090 > -99\n",
    "#\"\"\"\n",
    "\n",
    "#Then, query the database. The answer is a table that is being returned to a dataframe that we've named all_gals.\n",
    "all_gals = CasJobs.executeQuery(query, \"dr16\")\n",
    "\n",
    "print(\"SQL query finished.\")\n",
    "print(f\"SQL query returned {len(all_gals.index)} galaxies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe that is returned, named all_gals, holds the following quantities for each galaxy:\n",
    " * objra, objdec = The position of the galaxy. RA is the Right Ascension coordinate in degress, and DEC is the Declination corordiante in degrees\n",
    " * A = the asymmetry\n",
    " * As = the shape asymmetry at 180 degrees\n",
    " * As90 = the shape asymetry at 90 degrees\n",
    " * S = Smoothness parameter\n",
    " * G = Gini index\n",
    " * C2080, C5090 = The concentraion of light within a certain annulus\n",
    " * M20 = The 2nd moment of light\n",
    " * run, rerun, camccol, field = information about which part of the camera took the image\n",
    " \n",
    "Lets look at what all this data looks like, but first lets add a new column to the dataframe which contains the path to the image on SciServer. This will be useful later in the notebook.\n",
    "To do this we need the information about which part of the camera took the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to the dataframe, which contains the path to the image\n",
    "def makename(df):\n",
    "    root = \"/home/idies/workspace/sdss_das/das2/imaging/\"\n",
    "    df[\"fname\"] = df.apply(lambda row: root + f\"{int(row.run)}/{int(row.rerun)}/corr/{int(row.camcol)}/fpC-{int(row.run):06}-r{int(row.camcol)}-{int(row.field):04}.fit.gz\", axis=1)\n",
    "    return df\n",
    "\n",
    "# add filename column\n",
    "all_gals = makename(all_gals)\n",
    "# View the information of the first 10 galaxies retrieved\n",
    "all_gals[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following bit of code plots the 16 random galaxies from the data we downloaded.\n",
    "Everytime it is run it will return different galaxies.\n",
    "## Exercise:\n",
    "    1. Classify each image into its morphological type, i.e spiral, elliptical, ring or other. You may want to   refer to LINK to help with classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display some galaxies in a 4x4 grid\n",
    "fig, axs = plt.subplots(4, 4, figsize=(15, 15))\n",
    "numbers = np.random.randint(len(all_gals.index), size=16)\n",
    "axs = axs.ravel()\n",
    "i = 0\n",
    "width, height = 128, 128\n",
    "scale = 60. / width #  set image scale to that of 1 arcmin\n",
    "for i, idx in enumerate(numbers):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Read image {i+1} of 16\")\n",
    "    ra, dec = all_gals[\"objra\"].iloc[idx], all_gals[\"objdec\"].iloc[idx]\n",
    "    img = SkyServer.getJpegImgCutout(ra=ra, dec=dec, width=width, height=height, scale=scale,dataRelease='DR16')\n",
    "\n",
    "    axs[i].imshow(img, origin=\"lower\")\n",
    "    axs[i].set_title(f\"Galaxy number: {idx}\")\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "print(\"Plotting images...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of a single galaxy\n",
    "Take your favoutite galaxy number from the plots above and use it in the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_galaxy = all_gals.iloc[]\n",
    "filename = fav_galaxy[\"fname\"]\n",
    "ra, dec = fav_galaxy[\"objra\"], fav_galaxy[\"objdec\"]\n",
    "# read in image and crop to area of interest\n",
    "img = pmlsst.image.readImage(\"sdss\", filename, ra, dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the image\n",
    "First we preprocess the image so that it is suitable for analysis.\n",
    "This is done by first removing any source of light in the image that is not the \"main\" source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove external light sources\n",
    "img = pmlsst.imageutils.maskstarsSEG(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we estimate the value of the sky. This means we count all the values of the pixels that are not part of the galaxy. We then tak an average of these values to get out estimate for the value of the sky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate skybackground\n",
    "skybgr, skybgr_err, *_ = pmlsst.skyBackground.skybgr(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The penuktimate step is to calculate the galaxy mask. A galaxy mask is an image where all the pixels have the values 1 or 0. Where the mask is 1, then that part of the image belongs to the galaxy, where it is 0 then that pixel belongs to the sky.\n",
    "Defining a galaxy mask allows us to easily compute more complex parameters related to the galaxy when anaysing the images of the galaxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image where the only bright pixels are the pixels that belong to the galaxy\n",
    "mask = pmlsst.pixmap.pixelmap(img, skybgr + skybgr_err, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise:\n",
    "    1. Plot both the image of your favourite galaxy from above alongside its mask\n",
    "    2. Comment on the overall shape of the mask. How does your what your eye can see compare to what the \n",
    "       computer algorithm \"see\"?. You might want to play with the vmin and vmax values of the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image analysis\n",
    "In order to illustrate how the image analysis method works for galaxies, we will apply the technique to Emoji's.\n",
    "First we need to load some libraries to process the emojis so that they are in a suitable format for the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, color, transform\n",
    "# read in the two images and plot them\n",
    "smiley = io.imread(\"emoji-1.png\")\n",
    "heart = io.imread(\"emoji-2.png\")\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(smiley)\n",
    "axs[1].imshow(heart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that carries out all the processing steps for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed so that the results are repoducible\n",
    "np.random.seed(1)\n",
    "def preprocessEmoji(img):\n",
    "    # convert image to grayscale\n",
    "    emoji = color.rgb2gray(img)\n",
    "    # shrink image so that code can process image in a timely manner\n",
    "    emoji = transform.resize(emoji, (500, 500))\n",
    "    # add some noise to image so that code can process the images as expected\n",
    "    emoji += (1./50.) * np.random.standard_normal(size=(500, 500))\n",
    "    return emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how these preprocessing steps has affect the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "smiley = preprocessEmoji(smiley)\n",
    "heart = preprocessEmoji(heart)\n",
    "axs[0].imshow(smiley)\n",
    "axs[1].imshow(heart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before lets calculate the \"sky\" value and generate the image masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get \"sky\" estimates and generate masks\n",
    "skybgr, skybgr_err, *_ = pmlsst.skyBackground.skybgr(smiley)\n",
    "smileyMask = pmlsst.pixmap.pixelmap(smiley, skybgr + skybgr_err, 3)\n",
    "skybgr, skybgr_err, *_ = pmlsst.skyBackground.skybgr(heart)\n",
    "heartMask = pmlsst.pixmap.pixelmap(heart, skybgr + skybgr_err, 3)\n",
    "# plot masks\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(smileyMask)\n",
    "axs[1].imshow(heartMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally lets run the analysis code on the Emoji's. While the next step runs please continue to the next part of the text as this can take around a minute to print a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate asymmetries\n",
    "A, As, _ = pmlsst.asymmetry.calculateAsymmetries(smiley, smileyMask)\n",
    "print(f\"Smiley: A: {A:0.3f}, As: {As:.3f}\")\n",
    "A, As, _ = pmlsst.asymmetry.calculateAsymmetries(heart, heartMask)\n",
    "print(f\"Heart: A: {A:0.3f}, As: {As:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetry\n",
    "\n",
    "calculateAsymmetries, as the name implies, calculates several asymmetry parameters of the input image using the image and its mask. \n",
    "\n",
    "So why is calculating a galaxies (or Emoji's) asymmetry important? The asymmetry parameters give vital information about the shape of the galaxy, allowing astronomers to search for interesting galaxies. \n",
    "\n",
    "Of particular interest are galaxies where they have undergone a merger with another galaxy, or have been disturbed by another galaxy. Investigating these \"messed up\" galaxies allow astronomers to get insights into the life cycle of galaxies. \n",
    "\n",
    "These messed up galaxies are fairly easy to identify by eye, however to to the sheer number of galaxies detected in the SDSS database it is not possible for a person to go through all the galaxies by hand and pick out the interesting galaxies. We therefore rely on computer algorithms to do this for us.\n",
    "\n",
    "So how does a computer define asymmetry? We will explore this by first examining how a human does this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "    1. How many lines of symmetry do the two Emoji images have?\n",
    "    2. If the smiley was just a circle (i.e had no face) would it have any more symmetries?\n",
    "    3. How symmetric is your favourite galaxy from before. Does it have any lines of symmerty?\n",
    "    4. What process did you use to determine the lines of symmetry in the Emoji example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a feel for how a human might classify symmetry we can move on to programming the computer to find symmetries as well.\n",
    "Finding lines of symmetry computationally is not straight forward for complex shapes. \n",
    "We could do as you most likely did in your head, draw lines then mirror the image to see it is symmertic. However, to properly do this we would have to draw hundreds to thousands of lines and check each timne to see if any them give a line of symmetry.\n",
    "\n",
    "We therefore, use a quick way of checking the symmetry. We check if there is rotational symmetry.\n",
    "To achieve this we rotate the image by 180 degrees, and then take it away from the original image. To get a final number we then count up the number of pixels in the difference image.\n",
    "Below is a function that helps to do this. Note for the purposes of this notebook we do not calculate a final number as this is a bit more involved than can be done in an afternoon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotationalDifference(img, angle):\n",
    "    point = (250, 250)\n",
    "    rotate = transform.rotate(img, angle, center=point, preserve_range=True)\n",
    "    res = np.abs(img - rotate)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "    1. Calculate the asymmetry image using the above function and plot the result for the heart and simley face\n",
    "    2. Do the same but this time for the image masks\n",
    "    3. Note any difference in calculating the asymmetry for the images and the masks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two different ways of calculating asymmetry used above are called the Asymmetry (A) and the shape asymmetry (As). Asytmmetry (A), is the example above where we use the image as it is. In the case with the simley face, this led to a larger asymmetry value compared to that of its shape asymmetry due to the emoji's face contirbuting more to the overall asymmetry. In the case where the smiley's mask were used (shape asymmetry) this led to a smaller asymmerty as the internal features of the emoji do not contirbute to the asymmetry at all.\n",
    "Shape asymmetry is better at finding \"messed up\" galaxies as it places higher values on the overal shape of the galaxy, rather than its internal structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big data\n",
    "\n",
    "Now that you have an understanding of the tasks faced by astronomers in finding the right type galaxies to study, we will introduce some of the tools that help astronomers and other scientisits tackle \"big data\".\n",
    "\n",
    "The first such tool you have been using the wholetime you have been working on this notebook!\n",
    "As mentioned in the introduction, SDSS can generate upto 200Gb of data a night, meaning it is infeasible to store all the data it generates on your personal computer or laptop. \n",
    "Therefore, a new paradigm has been introduced where instead of taking the data to the code for analysis, we take the code to the data. \n",
    "This means that the data is stored on some large secure server somewhere, and you upload the code to the server and set it running. This allows the code to access the data without the need to download the data.\n",
    "So in using SciServer and this notebook you have unknowingly been using this paradigm without realising it!\n",
    "\n",
    "The next tool in the astronomers toolbox is the full utilisation of a computers Central processing unit (CPU). Nowadays, most CPU's are actually composed of two or more smaller CPU's, called cores. One reason modern CPU's are made up of multiple cores, is that it is cheaper and more energy efficent to bundle multiple cores into one CPU, than it is to make one really fast core.\n",
    "\n",
    "Running code on more than one core is called parallelisation of the code. Parallelisation of code is not always an easy task, and can require a complete rewrite of the code in order to make it work. Fortunatly for us the code we are using is classed \"embarrassingly parallel\". This means that is really esay to make parallel, as all we need to do is tell each core to analyse a different subset of images each. So if we use two cores we would expect the code to runs two times faster, if we used 8 cores it should run 8 times faster and so on.\n",
    "\n",
    "To investigate the idea of using the whole CPU vs parts of the whole CPU, we will time how long the code takes to execute, and investigate Amdahl's law: https://en.wikipedia.org/wiki/Amdahl%27s_law\n",
    "\n",
    "To time code we will use the time module, and the helper function pmlsst.helpers.analyseImage.\n",
    "The time module functions like a stopwatch. You have to start the timer just before the code start, thens stop the timer when the code finishes.\n",
    "An example of this is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "start = time.time()         # start timer\n",
    "for i in range(1000000):    # run code. In this case we calculate a list of squares\n",
    "    b.append(i**2)\n",
    "finish = time.time()        # stop timer\n",
    "totaltime = finish - start  # calculate time code ran for\n",
    "print(totaltime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define the speed up of a program executed in parallel as $S=\\frac{t_1}{t_n}$, where S is the speedup, $t_n$ is the time take to run the code on $n$ cores, and $t_1$ is the time taken to run the code on 1 core.\n",
    "So if a piece of code takes 10s to run on 1 core, and 5s to run on 2 cores, then the speed up is: $S=\\frac{10}{5}=2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "1. Using the following snippets of code, time how long it takes to analyse 50 images of galaxies on 1, 2, 3, 4, 6, 8, 10, 12, 14, 16, 18, and 20 cores. Add these times to the empty timings list below or store them via another method.\n",
    "2. Plot a graph of number of cores vs time for the above datapoints. Make sure your plot has appropriate labels and titles.\n",
    "3. Calculate the speed up for each data point. Then plot core number vs speed up.\n",
    "4. On this same plot, plot a straight line of y=mx. You may want to use np.linspace or np.arange to generate the data for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet create a list of filenames, and positions that analyseImage requires to run\n",
    "info = []\n",
    "for i in range(0, 50):\n",
    "    ra, dec = all_gals[\"objra\"].iloc[i], all_gals[\"objdec\"].iloc[i]\n",
    "    name = all_gals[\"fname\"].iloc[i]\n",
    "    info.append([name, ra, dec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run image analysis with n cores\n",
    "cores = 8\n",
    "with ProcessPoolExecutor(max_workers=cores) as pool:\n",
    "    pool.map(pmlsst.helpers.analyseImage, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = [1, 2, 3, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "timings = [, , , , , , , , , , , ]\n",
    "timings = np.array(timings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above exercises were for just 50 of the 4603 we downladed data about. In reality there are billions more galaxies in existence, and SDSS has observed well over 50 million.\n",
    "## Exercise\n",
    "1. Using the timing information you calculated above, what is the most efficent amount of cores to use?\n",
    "2. Using your answer from Q1, how long would it take to run the analysis code on all 4603 galaxies in the downloaded data. How long would it take to analyse 50 million galaxies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus material\n",
    "\n",
    "Amdahl's law gives the theoretical speed up we can expect from a program that is executed in parallel: \n",
    "$S=\\frac{1}{(1-p)+\\tfrac{p}{n}}$. Where $S$ is the speedup, $p$ is the parallel portion of the program, and $n$ is the number of cores used. We can use this equation, along with timing how long the code takes to execute on different amount of cores to get the maximum possible speedup.\n",
    "An example of this is, if the parallel portion of the code is 75% (0.75), and the number of cores it runs on is 5, then the maximum possible speed up is: $S=\\frac{1}{(1-0.75) + \\frac{0.75}{5}}=2.5$.\n",
    "In the net set of exercises we will explore both these equations, and how we can use them to gaugue the performance of running code in parallel.\n",
    "\n",
    "## Exercise\n",
    "\n",
    "1. Use Scipy's optimize.curve_fit [function](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html#scipy.optimize.curve_fit) and the amdahl function defiened below to fit Amdahl's law to your timing data to get the parallel portion of the code. Plot this alongside the figure from question 4 in the last exercise (HARD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amdahl(n, p):\n",
    "    return 1. / ((1. - p) + (p / n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
